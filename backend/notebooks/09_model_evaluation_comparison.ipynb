{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 09 - Model Evaluation & Comparison\n",
    "\n",
    "## Purpose\n",
    "Comprehensive evaluation and comparison of all ML models developed for the Smart Inventory Manager.\n",
    "\n",
    "## Models Evaluated\n",
    "1. Demand Forecasting Models\n",
    "2. ABC Classification\n",
    "3. Dead Stock Detection\n",
    "4. Customer Segmentation (RFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Load data\n",
    "DATA_DIR = Path('../..') / 'ml' / 'data' / 'processed'\n",
    "\n",
    "products = pd.read_csv(DATA_DIR / 'products.csv')\n",
    "inventory = pd.read_csv(DATA_DIR / 'inventory.csv')\n",
    "orders = pd.read_csv(DATA_DIR / 'orders.csv')\n",
    "order_items = pd.read_csv(DATA_DIR / 'order_items.csv')\n",
    "customers = pd.read_csv(DATA_DIR / 'customers.csv')\n",
    "\n",
    "orders['OrderDate'] = pd.to_datetime(orders['OrderDate'])\n",
    "full_orders = orders.merge(order_items, on='OrderID')\n",
    "full_orders = full_orders.merge(products, on='ProductID')\n",
    "\n",
    "print(\"Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Demand Forecasting Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare daily demand data\n",
    "daily_demand = full_orders.groupby([full_orders['OrderDate'].dt.date, 'ProductID'])['Quantity'].sum().reset_index()\n",
    "daily_demand.columns = ['Date', 'ProductID', 'Quantity']\n",
    "daily_demand['Date'] = pd.to_datetime(daily_demand['Date'])\n",
    "\n",
    "# Get top products\n",
    "top_products = full_orders.groupby('ProductID')['Quantity'].sum().nlargest(20).index.tolist()\n",
    "\n",
    "def evaluate_forecasting_models(product_id, test_days=30):\n",
    "    \"\"\"Evaluate all forecasting models for a product.\"\"\"\n",
    "    prod_data = daily_demand[daily_demand['ProductID'] == product_id].sort_values('Date')\n",
    "    \n",
    "    if len(prod_data) < 60:\n",
    "        return None\n",
    "    \n",
    "    # Fill missing dates\n",
    "    date_range = pd.date_range(prod_data['Date'].min(), prod_data['Date'].max())\n",
    "    prod_data = prod_data.set_index('Date').reindex(date_range, fill_value=0).reset_index()\n",
    "    prod_data.columns = ['Date', 'ProductID', 'Quantity']\n",
    "    \n",
    "    # Split\n",
    "    train = prod_data.iloc[:-test_days]\n",
    "    test = prod_data.iloc[-test_days:]\n",
    "    actual = test['Quantity'].values\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # 1. Moving Average (7-day)\n",
    "    ma_pred = prod_data['Quantity'].rolling(7).mean().iloc[-test_days:].values\n",
    "    mask = ~np.isnan(ma_pred)\n",
    "    if mask.sum() > 0:\n",
    "        mae = mean_absolute_error(actual[mask], ma_pred[mask])\n",
    "        results.append({'Model': 'MA(7)', 'MAE': mae, 'ProductID': product_id})\n",
    "    \n",
    "    # 2. Exponential Smoothing\n",
    "    alpha = 0.3\n",
    "    values = prod_data['Quantity'].values\n",
    "    smoothed = [values[0]]\n",
    "    for i in range(1, len(values)):\n",
    "        smoothed.append(alpha * values[i] + (1 - alpha) * smoothed[-1])\n",
    "    es_pred = smoothed[-test_days:]\n",
    "    mae = mean_absolute_error(actual, es_pred)\n",
    "    results.append({'Model': 'ES(0.3)', 'MAE': mae, 'ProductID': product_id})\n",
    "    \n",
    "    # 3. Linear Regression\n",
    "    train_copy = train.copy()\n",
    "    train_copy['DayIndex'] = (train_copy['Date'] - train_copy['Date'].min()).dt.days\n",
    "    X_train = train_copy[['DayIndex']].values\n",
    "    y_train = train_copy['Quantity'].values\n",
    "    \n",
    "    test_copy = test.copy()\n",
    "    test_copy['DayIndex'] = (test_copy['Date'] - train_copy['Date'].min()).dt.days\n",
    "    X_test = test_copy[['DayIndex']].values\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    lr_pred = np.maximum(model.predict(X_test), 0)\n",
    "    mae = mean_absolute_error(actual, lr_pred)\n",
    "    results.append({'Model': 'LinearReg', 'MAE': mae, 'ProductID': product_id})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate on multiple products\n",
    "all_results = []\n",
    "for product_id in top_products[:10]:\n",
    "    results = evaluate_forecasting_models(product_id)\n",
    "    if results:\n",
    "        all_results.extend(results)\n",
    "\n",
    "forecast_eval = pd.DataFrame(all_results)\n",
    "\n",
    "# Aggregate by model\n",
    "model_summary = forecast_eval.groupby('Model')['MAE'].agg(['mean', 'std', 'min', 'max']).round(4)\n",
    "print(\"\\n=== Forecasting Model Performance ===\")\n",
    "display(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecasting performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot of MAE by model\n",
    "forecast_eval.boxplot(column='MAE', by='Model', ax=axes[0])\n",
    "axes[0].set_title('MAE Distribution by Model')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Mean Absolute Error')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "# Bar chart of average MAE\n",
    "avg_mae = forecast_eval.groupby('Model')['MAE'].mean().sort_values()\n",
    "axes[1].barh(avg_mae.index, avg_mae.values)\n",
    "axes[1].set_title('Average MAE by Model')\n",
    "axes[1].set_xlabel('Mean Absolute Error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_forecast_model = avg_mae.idxmin()\n",
    "print(f\"\\nBest Forecasting Model: {best_forecast_model} (Avg MAE: {avg_mae.min():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. ABC Classification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABC Classification\n",
    "product_metrics = full_orders.groupby('ProductID').agg({\n",
    "    'TotalAmount': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).reset_index()\n",
    "product_metrics.columns = ['ProductID', 'Revenue', 'Units']\n",
    "product_metrics = product_metrics.sort_values('Revenue', ascending=False).reset_index(drop=True)\n",
    "\n",
    "total_revenue = product_metrics['Revenue'].sum()\n",
    "product_metrics['CumulativeRevenue'] = product_metrics['Revenue'].cumsum()\n",
    "product_metrics['CumulativePct'] = product_metrics['CumulativeRevenue'] / total_revenue * 100\n",
    "\n",
    "def assign_abc(pct):\n",
    "    if pct <= 80:\n",
    "        return 'A'\n",
    "    elif pct <= 95:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "\n",
    "product_metrics['ABC_Class'] = product_metrics['CumulativePct'].apply(assign_abc)\n",
    "\n",
    "# Validation metrics\n",
    "abc_validation = product_metrics.groupby('ABC_Class').agg({\n",
    "    'ProductID': 'count',\n",
    "    'Revenue': 'sum',\n",
    "    'Units': 'sum'\n",
    "}).reset_index()\n",
    "abc_validation.columns = ['Class', 'Products', 'Revenue', 'Units']\n",
    "abc_validation['Revenue_Pct'] = abc_validation['Revenue'] / abc_validation['Revenue'].sum() * 100\n",
    "abc_validation['Product_Pct'] = abc_validation['Products'] / abc_validation['Products'].sum() * 100\n",
    "\n",
    "print(\"\\n=== ABC Classification Validation ===\")\n",
    "display(abc_validation)\n",
    "\n",
    "# Pareto validation (80/20 rule)\n",
    "a_class = abc_validation[abc_validation['Class'] == 'A']\n",
    "pareto_ratio = a_class['Revenue_Pct'].values[0] / a_class['Product_Pct'].values[0]\n",
    "print(f\"\\nPareto Ratio (A-class): {pareto_ratio:.2f}\")\n",
    "print(f\"(Higher ratio = better concentration of value in fewer products)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Dead Stock Detection Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dead stock detection\n",
    "last_sale = full_orders.groupby('ProductID')['OrderDate'].max().reset_index()\n",
    "last_sale.columns = ['ProductID', 'LastSale']\n",
    "\n",
    "reference_date = orders['OrderDate'].max()\n",
    "last_sale['DaysSinceSale'] = (reference_date - last_sale['LastSale']).dt.days\n",
    "\n",
    "# Merge with inventory\n",
    "inventory_status = products.merge(inventory, on='ProductID', how='left')\n",
    "inventory_status = inventory_status.merge(last_sale, on='ProductID', how='left')\n",
    "\n",
    "# Classify dead stock (90+ days without sale)\n",
    "inventory_status['IsDeadStock'] = (\n",
    "    (inventory_status['DaysSinceSale'] >= 90) | \n",
    "    (inventory_status['DaysSinceSale'].isna())\n",
    ") & (inventory_status['Current_Stock'] > 0)\n",
    "\n",
    "dead_stock_summary = pd.DataFrame({\n",
    "    'Metric': ['Total Products with Stock', 'Dead Stock Products', 'Dead Stock %', \n",
    "               'Dead Stock Value ($)', 'At-Risk Products (60-90 days)'],\n",
    "    'Value': [\n",
    "        (inventory_status['Current_Stock'] > 0).sum(),\n",
    "        inventory_status['IsDeadStock'].sum(),\n",
    "        f\"{inventory_status['IsDeadStock'].mean() * 100:.1f}%\",\n",
    "        f\"${(inventory_status[inventory_status['IsDeadStock']]['Current_Stock'] * inventory_status[inventory_status['IsDeadStock']]['Cost_Price'].fillna(0)).sum():,.2f}\",\n",
    "        ((inventory_status['DaysSinceSale'] >= 60) & (inventory_status['DaysSinceSale'] < 90)).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Dead Stock Detection Results ===\")\n",
    "display(dead_stock_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dead stock by category\n",
    "dead_by_category = inventory_status[inventory_status['IsDeadStock']].groupby('Category').size()\n",
    "total_by_category = inventory_status[inventory_status['Current_Stock'] > 0].groupby('Category').size()\n",
    "dead_pct_by_category = (dead_by_category / total_by_category * 100).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "dead_pct_by_category.plot(kind='barh')\n",
    "plt.title('Dead Stock Percentage by Category')\n",
    "plt.xlabel('Dead Stock %')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Customer Segmentation (RFM) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM Analysis\n",
    "reference_date = orders['OrderDate'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "rfm = full_orders.groupby('CustomerID').agg({\n",
    "    'OrderDate': lambda x: (reference_date - x.max()).days,\n",
    "    'OrderID': 'nunique',\n",
    "    'TotalAmount': 'sum'\n",
    "}).reset_index()\n",
    "rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# RFM Scoring\n",
    "rfm['R_Score'] = pd.qcut(rfm['Recency'], q=5, labels=[5, 4, 3, 2, 1]).astype(int)\n",
    "rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method='first'), q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "rfm['M_Score'] = pd.qcut(rfm['Monetary'].rank(method='first'), q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "rfm['RFM_Score'] = rfm['R_Score'] + rfm['F_Score'] + rfm['M_Score']\n",
    "\n",
    "# Segment customers\n",
    "def segment(row):\n",
    "    r, f, m = row['R_Score'], row['F_Score'], row['M_Score']\n",
    "    if r >= 4 and f >= 4 and m >= 4:\n",
    "        return 'Champions'\n",
    "    elif r >= 4 and f >= 3:\n",
    "        return 'Loyal'\n",
    "    elif r <= 2 and f >= 3:\n",
    "        return 'At Risk'\n",
    "    elif r <= 2 and f <= 2:\n",
    "        return 'Lost'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "rfm['Segment'] = rfm.apply(segment, axis=1)\n",
    "\n",
    "# Segment evaluation\n",
    "segment_eval = rfm.groupby('Segment').agg({\n",
    "    'CustomerID': 'count',\n",
    "    'Monetary': ['sum', 'mean'],\n",
    "    'Frequency': 'mean'\n",
    "}).round(2)\n",
    "segment_eval.columns = ['Customers', 'Total_Revenue', 'Avg_Revenue', 'Avg_Frequency']\n",
    "segment_eval = segment_eval.sort_values('Total_Revenue', ascending=False)\n",
    "\n",
    "print(\"\\n=== Customer Segmentation Results ===\")\n",
    "display(segment_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segments\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Customer distribution\n",
    "segment_counts = rfm['Segment'].value_counts()\n",
    "axes[0].pie(segment_counts, labels=segment_counts.index, autopct='%1.1f%%')\n",
    "axes[0].set_title('Customer Distribution by Segment')\n",
    "\n",
    "# Revenue distribution\n",
    "segment_revenue = rfm.groupby('Segment')['Monetary'].sum().sort_values(ascending=True)\n",
    "axes[1].barh(segment_revenue.index, segment_revenue.values / 1000)\n",
    "axes[1].set_title('Revenue by Segment')\n",
    "axes[1].set_xlabel('Revenue ($K)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Overall Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n=== 1. DEMAND FORECASTING ===\")\n",
    "print(f\"Best Model: {best_forecast_model}\")\n",
    "print(f\"Average MAE: {avg_mae.min():.4f}\")\n",
    "print(\"Recommendation: Use for inventory replenishment planning\")\n",
    "\n",
    "print(\"\\n=== 2. ABC CLASSIFICATION ===\")\n",
    "a_data = abc_validation[abc_validation['Class'] == 'A']\n",
    "print(f\"A-Class Products: {a_data['Products'].values[0]} ({a_data['Product_Pct'].values[0]:.1f}%)\")\n",
    "print(f\"A-Class Revenue: ${a_data['Revenue'].values[0]:,.2f} ({a_data['Revenue_Pct'].values[0]:.1f}%)\")\n",
    "print(f\"Pareto Efficiency: {pareto_ratio:.2f}x\")\n",
    "print(\"Recommendation: Prioritize A-class items for inventory optimization\")\n",
    "\n",
    "print(\"\\n=== 3. DEAD STOCK DETECTION ===\")\n",
    "dead_count = inventory_status['IsDeadStock'].sum()\n",
    "dead_pct = inventory_status['IsDeadStock'].mean() * 100\n",
    "print(f\"Dead Stock Items: {dead_count} ({dead_pct:.1f}%)\")\n",
    "print(\"Recommendation: Implement clearance strategies for dead stock\")\n",
    "\n",
    "print(\"\\n=== 4. CUSTOMER SEGMENTATION ===\")\n",
    "champions = len(rfm[rfm['Segment'] == 'Champions'])\n",
    "at_risk = len(rfm[rfm['Segment'] == 'At Risk'])\n",
    "print(f\"Champions: {champions} customers\")\n",
    "print(f\"At Risk: {at_risk} customers\")\n",
    "print(\"Recommendation: Focus retention efforts on At-Risk segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Forecasting model comparison\n",
    "avg_mae.plot(kind='bar', ax=axes[0, 0], color=['green' if x == avg_mae.min() else 'gray' for x in avg_mae])\n",
    "axes[0, 0].set_title('Forecasting Model MAE')\n",
    "axes[0, 0].set_ylabel('MAE')\n",
    "axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. ABC distribution\n",
    "abc_validation.plot(x='Class', y=['Product_Pct', 'Revenue_Pct'], kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('ABC Distribution (Products vs Revenue)')\n",
    "axes[0, 1].set_ylabel('Percentage')\n",
    "axes[0, 1].legend(['Products %', 'Revenue %'])\n",
    "axes[0, 1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 3. Dead stock by category (top 5)\n",
    "dead_pct_by_category.head(5).plot(kind='bar', ax=axes[1, 0], color='red', alpha=0.7)\n",
    "axes[1, 0].set_title('Top 5 Categories - Dead Stock %')\n",
    "axes[1, 0].set_ylabel('Dead Stock %')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Customer segments\n",
    "segment_counts.plot(kind='bar', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Customer Segments')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ACTIONABLE INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. INVENTORY OPTIMIZATION:\n",
    "   - Use Linear Regression / Moving Average for demand forecasting\n",
    "   - Focus on A-class products for safety stock optimization\n",
    "   - Review and liquidate dead stock to free up capital\n",
    "\n",
    "2. CUSTOMER RETENTION:\n",
    "   - Prioritize Champions segment for loyalty programs\n",
    "   - Re-engage At-Risk customers with targeted promotions\n",
    "   - Monitor Loyal customers for potential upgrades\n",
    "\n",
    "3. PRODUCT STRATEGY:\n",
    "   - Invest in A-class product availability\n",
    "   - Consider discontinuing chronic C-class dead stock\n",
    "   - Review B-class products for potential A-class promotion\n",
    "\n",
    "4. OPERATIONAL IMPROVEMENTS:\n",
    "   - Implement automated reorder alerts for A-class items\n",
    "   - Weekly dead stock review process\n",
    "   - Monthly customer segment analysis\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
