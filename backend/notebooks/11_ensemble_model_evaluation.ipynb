{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Ensemble Model Evaluation\n",
    "\n",
    "## SARIMA + Prophet + LSTM Ensemble\n",
    "\n",
    "**Target: SMAPE < 20%**\n",
    "\n",
    "This notebook evaluates the hybrid ensemble forecasting model that combines:\n",
    "1. **SARIMA** - Statistical time series model (trend + seasonality)\n",
    "2. **Prophet** - Facebook's decomposition model (trend + multiple seasonalities)\n",
    "3. **LSTM** - Deep learning for complex non-linear patterns\n",
    "\n",
    "The ensemble uses intelligent weight optimization based on validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the ml directory to path\n",
    "ml_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'app', 'ml'))\n",
    "sys.path.insert(0, ml_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import forecasters\n",
    "from sarima_forecaster import SARIMAForecaster, CategoryForecaster\n",
    "\n",
    "# Try importing ensemble components\n",
    "try:\n",
    "    from prophet_forecaster import ProphetForecaster\n",
    "    PROPHET_AVAILABLE = True\n",
    "    print(\"âœ“ Prophet available\")\n",
    "except ImportError as e:\n",
    "    PROPHET_AVAILABLE = False\n",
    "    print(f\"âœ— Prophet not available: {e}\")\n",
    "    print(\"  Install with: pip install prophet\")\n",
    "\n",
    "try:\n",
    "    from lstm_forecaster import LSTMForecaster\n",
    "    LSTM_AVAILABLE = True\n",
    "    print(\"âœ“ LSTM/TensorFlow available\")\n",
    "except ImportError as e:\n",
    "    LSTM_AVAILABLE = False\n",
    "    print(f\"âœ— LSTM not available: {e}\")\n",
    "    print(\"  Install with: pip install tensorflow\")\n",
    "\n",
    "try:\n",
    "    from ensemble_forecaster import EnsembleForecaster, CategoryEnsembleForecaster\n",
    "    ENSEMBLE_AVAILABLE = PROPHET_AVAILABLE and LSTM_AVAILABLE\n",
    "    if ENSEMBLE_AVAILABLE:\n",
    "        print(\"âœ“ Ensemble forecaster available\")\n",
    "except ImportError as e:\n",
    "    ENSEMBLE_AVAILABLE = False\n",
    "    print(f\"âœ— Ensemble not available: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "DATA_PATH = '../../../ml/data/raw/olist_public_dataset_v2.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "print(f\"Loaded {len(df):,} records\")\n",
    "print(f\"Date range: {df['order_date'].min()} to {df['order_date'].max()}\")\n",
    "print(f\"\\nCategories ({df['category'].nunique()}):\")\n",
    "for cat in df['category'].unique():\n",
    "    print(f\"  - {cat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare weekly data by category\n",
    "def prepare_weekly_data(df, category):\n",
    "    \"\"\"Aggregate to weekly demand for a category.\"\"\"\n",
    "    cat_data = df[df['category'] == category].copy()\n",
    "    weekly = cat_data.groupby(pd.Grouper(key='order_date', freq='W'))['quantity'].sum()\n",
    "    weekly = weekly[weekly > 0]  # Remove zero weeks\n",
    "    return weekly\n",
    "\n",
    "# Helper function for SMAPE\n",
    "def calculate_smape(actual, predicted):\n",
    "    \"\"\"Calculate Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    denominator = (np.abs(actual) + np.abs(predicted)) / 2.0\n",
    "    denominator = np.where(denominator == 0, 1, denominator)\n",
    "    return np.mean(np.abs(actual - predicted) / denominator) * 100\n",
    "\n",
    "# Get all categories\n",
    "categories = df['category'].unique()\n",
    "print(f\"Will evaluate {len(categories)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Individual Model Performance\n",
    "\n",
    "First, let's evaluate each model individually on a holdout test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate individual models\n",
    "TEST_SIZE = 8  # 8 weeks holdout\n",
    "\n",
    "results = []\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {category}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get weekly data\n",
    "    weekly_data = prepare_weekly_data(df, category)\n",
    "    \n",
    "    if len(weekly_data) < 30:\n",
    "        print(f\"Skipping - insufficient data ({len(weekly_data)} weeks)\")\n",
    "        continue\n",
    "    \n",
    "    # Train/test split\n",
    "    train = weekly_data[:-TEST_SIZE]\n",
    "    test = weekly_data[-TEST_SIZE:]\n",
    "    \n",
    "    cat_results = {'category': category, 'test_size': len(test)}\n",
    "    \n",
    "    # 1. SARIMA\n",
    "    try:\n",
    "        sarima = SARIMAForecaster(seasonal_period=52, use_log_transform=True)\n",
    "        sarima.fit(train)\n",
    "        sarima_pred, _, _ = sarima.predict(steps=len(test))\n",
    "        sarima_pred.index = test.index\n",
    "        cat_results['sarima_smape'] = calculate_smape(test.values, sarima_pred.values)\n",
    "        print(f\"  SARIMA SMAPE: {cat_results['sarima_smape']:.2f}%\")\n",
    "    except Exception as e:\n",
    "        cat_results['sarima_smape'] = None\n",
    "        print(f\"  SARIMA failed: {e}\")\n",
    "    \n",
    "    # 2. Prophet\n",
    "    if PROPHET_AVAILABLE:\n",
    "        try:\n",
    "            prophet = ProphetForecaster()\n",
    "            prophet.fit(train)\n",
    "            prophet_pred, _, _ = prophet.predict(steps=len(test))\n",
    "            prophet_pred.index = test.index\n",
    "            cat_results['prophet_smape'] = calculate_smape(test.values, prophet_pred.values)\n",
    "            print(f\"  Prophet SMAPE: {cat_results['prophet_smape']:.2f}%\")\n",
    "        except Exception as e:\n",
    "            cat_results['prophet_smape'] = None\n",
    "            print(f\"  Prophet failed: {e}\")\n",
    "    \n",
    "    # 3. LSTM\n",
    "    if LSTM_AVAILABLE:\n",
    "        try:\n",
    "            lstm = LSTMForecaster(lookback=12, lstm_units=64, epochs=50)\n",
    "            lstm.fit(train)\n",
    "            lstm_pred, _, _ = lstm.predict(steps=len(test))\n",
    "            lstm_pred.index = test.index\n",
    "            cat_results['lstm_smape'] = calculate_smape(test.values, lstm_pred.values)\n",
    "            print(f\"  LSTM SMAPE: {cat_results['lstm_smape']:.2f}%\")\n",
    "        except Exception as e:\n",
    "            cat_results['lstm_smape'] = None\n",
    "            print(f\"  LSTM failed: {e}\")\n",
    "    \n",
    "    results.append(cat_results)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Individual Model Results\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ensemble Model Training & Evaluation\n",
    "\n",
    "Now let's train the ensemble model and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENSEMBLE_AVAILABLE:\n",
    "    ensemble_results = []\n",
    "    \n",
    "    for category in categories:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training Ensemble: {category}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        weekly_data = prepare_weekly_data(df, category)\n",
    "        \n",
    "        if len(weekly_data) < 30:\n",
    "            print(f\"Skipping - insufficient data\")\n",
    "            continue\n",
    "        \n",
    "        # Train/test split\n",
    "        train = weekly_data[:-TEST_SIZE]\n",
    "        test = weekly_data[-TEST_SIZE:]\n",
    "        \n",
    "        try:\n",
    "            # Train ensemble\n",
    "            ensemble = EnsembleForecaster(\n",
    "                optimization_method='validation',\n",
    "                validation_size=8\n",
    "            )\n",
    "            ensemble.fit(train, category=category)\n",
    "            \n",
    "            # Get predictions\n",
    "            ensemble_pred, lower, upper = ensemble.predict(steps=len(test))\n",
    "            ensemble_pred.index = test.index\n",
    "            \n",
    "            # Calculate SMAPE\n",
    "            ensemble_smape = calculate_smape(test.values, ensemble_pred.values)\n",
    "            \n",
    "            # Get weights\n",
    "            weights = ensemble.get_model_weights()\n",
    "            \n",
    "            ensemble_results.append({\n",
    "                'category': category,\n",
    "                'ensemble_smape': ensemble_smape,\n",
    "                'sarima_weight': weights['sarima'],\n",
    "                'prophet_weight': weights['prophet'],\n",
    "                'lstm_weight': weights['lstm']\n",
    "            })\n",
    "            \n",
    "            print(f\"  Ensemble SMAPE: {ensemble_smape:.2f}%\")\n",
    "            print(f\"  Weights - SARIMA: {weights['sarima']:.3f}, Prophet: {weights['prophet']:.3f}, LSTM: {weights['lstm']:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Ensemble failed: {e}\")\n",
    "            ensemble_results.append({\n",
    "                'category': category,\n",
    "                'ensemble_smape': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    ensemble_df = pd.DataFrame(ensemble_results)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Ensemble Model Results\")\n",
    "    print(\"=\"*60)\n",
    "    print(ensemble_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Ensemble not available - install prophet and tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison: SARIMA vs Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENSEMBLE_AVAILABLE and len(ensemble_results) > 0:\n",
    "    # Merge results\n",
    "    comparison = pd.merge(\n",
    "        results_df[['category', 'sarima_smape']],\n",
    "        ensemble_df[['category', 'ensemble_smape', 'sarima_weight', 'prophet_weight', 'lstm_weight']],\n",
    "        on='category',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Calculate improvement\n",
    "    comparison['improvement'] = comparison['sarima_smape'] - comparison['ensemble_smape']\n",
    "    comparison['improvement_pct'] = (comparison['improvement'] / comparison['sarima_smape']) * 100\n",
    "    \n",
    "    # Target check\n",
    "    comparison['meets_target'] = comparison['ensemble_smape'] < 20\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SARIMA vs Ensemble Comparison\")\n",
    "    print(\"=\"*80)\n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Average SARIMA SMAPE:   {comparison['sarima_smape'].mean():.2f}%\")\n",
    "    print(f\"Average Ensemble SMAPE: {comparison['ensemble_smape'].mean():.2f}%\")\n",
    "    print(f\"Average Improvement:    {comparison['improvement'].mean():.2f}% ({comparison['improvement_pct'].mean():.1f}% reduction)\")\n",
    "    print(f\"\\nCategories meeting <20% target: {comparison['meets_target'].sum()}/{len(comparison)}\")\n",
    "    print(f\"Categories meeting <25% target: {(comparison['ensemble_smape'] < 25).sum()}/{len(comparison)}\")\n",
    "else:\n",
    "    print(\"Cannot compare - ensemble results not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENSEMBLE_AVAILABLE and len(ensemble_results) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. SMAPE Comparison Bar Chart\n",
    "    ax1 = axes[0, 0]\n",
    "    x = np.arange(len(comparison))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, comparison['sarima_smape'], width, label='SARIMA', color='steelblue', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, comparison['ensemble_smape'], width, label='Ensemble', color='forestgreen', alpha=0.8)\n",
    "    \n",
    "    ax1.axhline(y=20, color='red', linestyle='--', label='Target (20%)')\n",
    "    ax1.set_xlabel('Category')\n",
    "    ax1.set_ylabel('SMAPE (%)')\n",
    "    ax1.set_title('SMAPE Comparison: SARIMA vs Ensemble')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([c[:15] for c in comparison['category']], rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(0, max(comparison['sarima_smape'].max(), comparison['ensemble_smape'].max()) * 1.2)\n",
    "    \n",
    "    # 2. Improvement Chart\n",
    "    ax2 = axes[0, 1]\n",
    "    colors = ['forestgreen' if imp > 0 else 'crimson' for imp in comparison['improvement']]\n",
    "    ax2.barh(comparison['category'], comparison['improvement'], color=colors, alpha=0.8)\n",
    "    ax2.axvline(x=0, color='black', linewidth=0.5)\n",
    "    ax2.set_xlabel('SMAPE Improvement (percentage points)')\n",
    "    ax2.set_title('Ensemble Improvement over SARIMA')\n",
    "    ax2.set_yticklabels([c[:20] for c in comparison['category']])\n",
    "    \n",
    "    # 3. Weight Distribution\n",
    "    ax3 = axes[1, 0]\n",
    "    weight_data = comparison[['sarima_weight', 'prophet_weight', 'lstm_weight']].mean()\n",
    "    colors_pie = ['steelblue', 'coral', 'forestgreen']\n",
    "    ax3.pie(weight_data, labels=['SARIMA', 'Prophet', 'LSTM'], autopct='%1.1f%%', colors=colors_pie)\n",
    "    ax3.set_title('Average Model Weights')\n",
    "    \n",
    "    # 4. Before/After Summary\n",
    "    ax4 = axes[1, 1]\n",
    "    summary_data = {\n",
    "        'Metric': ['Avg SMAPE', 'Min SMAPE', 'Max SMAPE', 'Std Dev', 'Meeting <20% Target'],\n",
    "        'SARIMA': [\n",
    "            f\"{comparison['sarima_smape'].mean():.1f}%\",\n",
    "            f\"{comparison['sarima_smape'].min():.1f}%\",\n",
    "            f\"{comparison['sarima_smape'].max():.1f}%\",\n",
    "            f\"{comparison['sarima_smape'].std():.1f}%\",\n",
    "            f\"{(comparison['sarima_smape'] < 20).sum()}/{len(comparison)}\"\n",
    "        ],\n",
    "        'Ensemble': [\n",
    "            f\"{comparison['ensemble_smape'].mean():.1f}%\",\n",
    "            f\"{comparison['ensemble_smape'].min():.1f}%\",\n",
    "            f\"{comparison['ensemble_smape'].max():.1f}%\",\n",
    "            f\"{comparison['ensemble_smape'].std():.1f}%\",\n",
    "            f\"{comparison['meets_target'].sum()}/{len(comparison)}\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    ax4.axis('off')\n",
    "    table = ax4.table(\n",
    "        cellText=[[summary_data['Metric'][i], summary_data['SARIMA'][i], summary_data['Ensemble'][i]] for i in range(5)],\n",
    "        colLabels=['Metric', 'SARIMA', 'Ensemble'],\n",
    "        loc='center',\n",
    "        cellLoc='center'\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.8)\n",
    "    ax4.set_title('Performance Summary', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ensemble_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ“ Saved: ensemble_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Actual vs Predicted (Best Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENSEMBLE_AVAILABLE and len(ensemble_results) > 0:\n",
    "    # Find best performing category\n",
    "    best_category = comparison.loc[comparison['ensemble_smape'].idxmin(), 'category']\n",
    "    best_smape = comparison['ensemble_smape'].min()\n",
    "    \n",
    "    print(f\"Best performing category: {best_category} (SMAPE: {best_smape:.2f}%)\")\n",
    "    \n",
    "    # Get data and train ensemble\n",
    "    weekly_data = prepare_weekly_data(df, best_category)\n",
    "    train = weekly_data[:-TEST_SIZE]\n",
    "    test = weekly_data[-TEST_SIZE:]\n",
    "    \n",
    "    # Train models\n",
    "    sarima = SARIMAForecaster(seasonal_period=52, use_log_transform=True)\n",
    "    sarima.fit(train)\n",
    "    sarima_pred, sarima_lower, sarima_upper = sarima.predict(steps=len(test))\n",
    "    sarima_pred.index = test.index\n",
    "    \n",
    "    ensemble = EnsembleForecaster(optimization_method='validation', validation_size=8)\n",
    "    ensemble.fit(train, category=best_category)\n",
    "    ensemble_pred, ensemble_lower, ensemble_upper = ensemble.predict(steps=len(test))\n",
    "    ensemble_pred.index = test.index\n",
    "    ensemble_lower.index = test.index\n",
    "    ensemble_upper.index = test.index\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # SARIMA\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(train.index[-20:], train.values[-20:], 'b-', label='Training Data', linewidth=2)\n",
    "    ax1.plot(test.index, test.values, 'g-', label='Actual', linewidth=2, marker='o')\n",
    "    ax1.plot(sarima_pred.index, sarima_pred.values, 'r--', label='SARIMA Forecast', linewidth=2, marker='s')\n",
    "    ax1.axvline(x=train.index[-1], color='gray', linestyle=':', alpha=0.5)\n",
    "    ax1.set_title(f'{best_category} - SARIMA Forecast\\nSMAPE: {calculate_smape(test.values, sarima_pred.values):.2f}%')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Weekly Demand')\n",
    "    ax1.legend()\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Ensemble\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(train.index[-20:], train.values[-20:], 'b-', label='Training Data', linewidth=2)\n",
    "    ax2.plot(test.index, test.values, 'g-', label='Actual', linewidth=2, marker='o')\n",
    "    ax2.plot(ensemble_pred.index, ensemble_pred.values, 'r--', label='Ensemble Forecast', linewidth=2, marker='s')\n",
    "    ax2.fill_between(ensemble_lower.index, ensemble_lower.values, ensemble_upper.values, color='red', alpha=0.2, label='95% CI')\n",
    "    ax2.axvline(x=train.index[-1], color='gray', linestyle=':', alpha=0.5)\n",
    "    ax2.set_title(f'{best_category} - Ensemble Forecast\\nSMAPE: {calculate_smape(test.values, ensemble_pred.values):.2f}%')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Weekly Demand')\n",
    "    ax2.legend()\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ensemble_actual_vs_predicted.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ“ Saved: ensemble_actual_vs_predicted.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS: HYBRID ENSEMBLE MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if ENSEMBLE_AVAILABLE and len(ensemble_results) > 0:\n",
    "    print(f\"\\nðŸ“Š MODEL PERFORMANCE\")\n",
    "    print(f\"-\" * 40)\n",
    "    print(f\"SARIMA Only:\")\n",
    "    print(f\"  â€¢ Average SMAPE: {comparison['sarima_smape'].mean():.2f}%\")\n",
    "    print(f\"  â€¢ Categories <20% SMAPE: {(comparison['sarima_smape'] < 20).sum()}/{len(comparison)}\")\n",
    "    print(f\"\\nEnsemble (SARIMA + Prophet + LSTM):\")\n",
    "    print(f\"  â€¢ Average SMAPE: {comparison['ensemble_smape'].mean():.2f}%\")\n",
    "    print(f\"  â€¢ Categories <20% SMAPE: {comparison['meets_target'].sum()}/{len(comparison)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ IMPROVEMENT\")\n",
    "    print(f\"-\" * 40)\n",
    "    print(f\"  â€¢ Absolute: {comparison['improvement'].mean():.2f} percentage points\")\n",
    "    print(f\"  â€¢ Relative: {comparison['improvement_pct'].mean():.1f}% reduction in error\")\n",
    "    \n",
    "    print(f\"\\nâš–ï¸ AVERAGE MODEL WEIGHTS\")\n",
    "    print(f\"-\" * 40)\n",
    "    print(f\"  â€¢ SARIMA:  {comparison['sarima_weight'].mean()*100:.1f}%\")\n",
    "    print(f\"  â€¢ Prophet: {comparison['prophet_weight'].mean()*100:.1f}%\")\n",
    "    print(f\"  â€¢ LSTM:    {comparison['lstm_weight'].mean()*100:.1f}%\")\n",
    "    \n",
    "    target_met = comparison['meets_target'].sum() == len(comparison)\n",
    "    print(f\"\\nðŸŽ¯ TARGET: SMAPE < 20%\")\n",
    "    print(f\"-\" * 40)\n",
    "    if target_met:\n",
    "        print(f\"  âœ… TARGET ACHIEVED! All categories under 20% SMAPE\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ {comparison['meets_target'].sum()}/{len(comparison)} categories meeting target\")\n",
    "        above_target = comparison[~comparison['meets_target']][['category', 'ensemble_smape']]\n",
    "        print(f\"  Categories above target:\")\n",
    "        for _, row in above_target.iterrows():\n",
    "            print(f\"    - {row['category']}: {row['ensemble_smape']:.2f}%\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Ensemble evaluation could not be completed.\")\n",
    "    print(\"   Please install required dependencies:\")\n",
    "    print(\"   pip install prophet tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "if ENSEMBLE_AVAILABLE and len(ensemble_results) > 0:\n",
    "    comparison.to_csv('ensemble_evaluation_results.csv', index=False)\n",
    "    print(\"âœ“ Saved: ensemble_evaluation_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
